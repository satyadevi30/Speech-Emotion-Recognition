# -*- coding: utf-8 -*-
"""speech emotion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18hmTrP2AYYukwaJEOfBKPzkXE_-MQZe-

# ***Speech Emotion Recognition***

## import libraries
"""

import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
import librosa
import librosa.display
from IPython.display import Audio
import warnings
warnings.filterwarnings("ignore")
from keras import utils

"""# Load the Dataset"""

import google.colab as colab
colab.drive.mount('/content/drive')

paths=[]
labels=[]
for dirname, _, filenames in os.walk('/content/drive/MyDrive/TESS Toronto emotional speech set data'):
    for filename in filenames:
        paths.append(os.path.join(dirname, filename))
        label=filename.split('_')[-1]
        label=label.split('.')[0]
        labels.append(label.lower())
    if len(paths)==5601:
        break
print('Dataset is loaded')

"""# Exploratory Data Analysis"""

len(paths)

paths[:5]

labels[:5]

df=pd.DataFrame()
df['speech']=paths
df['label']=labels
df.head()

df['label'].value_counts()

df['label_count']=df['label'].value_counts
df.drop('label_count',axis=1)

df.info()

sns.countplot(data=df,x='label')

df

def waveplot(data, sr, emotion):
    plt.figure(figsize=(10, 4))
    plt.title(emotion, size=20)
    librosa.display.waveshow(data, sr=sr)
    plt.show()

def spectogram(data, sr, emotion):
    x = librosa.stft(data)
    xdb = librosa.amplitude_to_db(abs(x))
    plt.figure(figsize=(10, 4))
    plt.title(emotion, size=20)
    librosa.display.specshow(xdb, sr=sr, x_axis='time', y_axis='log')
    plt.colorbar()

emotion = 'disgust'
path = df['speech'][df['label'] == emotion].iloc[0]
data, sampling_rate = librosa.load(path)
waveplot(data, sampling_rate, emotion)
spectogram(data, sampling_rate, emotion)
Audio(path)

emotion = 'ps'
path = df['speech'][df['label'] == emotion].iloc[0]
data, sampling_rate = librosa.load(path)
waveplot(data, sampling_rate, emotion)
spectogram(data, sampling_rate, emotion)
Audio(path)

emotion = 'angry'
path = df['speech'][df['label'] == emotion].iloc[0]
data, sampling_rate = librosa.load(path)
waveplot(data, sampling_rate, emotion)
spectogram(data, sampling_rate, emotion)
Audio(path)

emotion = 'fear'
path = df['speech'][df['label'] == emotion].iloc[0]
data, sampling_rate = librosa.load(path)
waveplot(data, sampling_rate, emotion)
spectogram(data, sampling_rate, emotion)
Audio(path)

emotion = 'sad'
path = df['speech'][df['label'] == emotion].iloc[0]
data, sampling_rate = librosa.load(path)
waveplot(data, sampling_rate, emotion)
spectogram(data, sampling_rate, emotion)
Audio(path)

emotion = 'neutral'
path = df['speech'][df['label'] == emotion].iloc[0]
data, sampling_rate = librosa.load(path)
waveplot(data, sampling_rate, emotion)
spectogram(data, sampling_rate, emotion)
Audio(path)

emotion = 'fear (1)'
path = df['speech'][df['label'] == emotion].iloc[0]
data, sampling_rate = librosa.load(path)
waveplot(data, sampling_rate, emotion)
spectogram(data, sampling_rate, emotion)
Audio(path)

emotion = 'happy'
path = df['speech'][df['label'] == emotion].iloc[0]
data, sampling_rate = librosa.load(path)
waveplot(data, sampling_rate, emotion)
spectogram(data, sampling_rate, emotion)
Audio(path)

"""# Feature Extraction"""

def extract_mfcc(filename):
  y,sr=librosa.load(filename, duration=3, offset=0.5)
  mfcc=np.mean(librosa.feature.mfcc(y=y,sr=sr, n_mfcc=40).T, axis=0)
  return mfcc
extract_mfcc(df['speech'][0])

X_mfcc=df['speech'].apply(lambda x:extract_mfcc(x))
X_mfcc
X=[x for x in X_mfcc]
X=np.array(X)
X.shape

X=[x for x in X_mfcc]
X=np.array(X)
X.shape
#input split
X=np.expand_dims(X,-1)
X.shape

from sklearn.preprocessing import OneHotEncoder
enc=OneHotEncoder()
y=enc.fit_transform(df[['label']])
y=y.toarray()
y.shape

import tensorflow as tf
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout
from sklearn.model_selection import train_test_split

from keras.utils import to_categorical
# Example data
X = np.random.rand(1000, 10, 50)  # 1000 samples, 10 timesteps, 50 features
y = np.random.randint(0, 2, 1000)  # 1000 samples, binary classification

# One-hot encode the labels
y = to_categorical(y, num_classes=2)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Ensure data is in float32 format
X_train = np.array(X_train).astype('float32')
X_test = np.array(X_test).astype('float32')
y_train = np.array(y_train).astype('float32')  # or 'int32' depending on your task
y_test = np.array(y_test).astype('float32')    # or 'int32'

# Convert to TensorFlow tensors (if necessary)
X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)
X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)
y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)  # or 'int32'
y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)    # or 'int32'

"""# Create the LSTM model"""

# Build the LSTM model
model = Sequential()
model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False))
model.add(Dropout(0.5))
model.add(Dense(2, activation='softmax'))
# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# Train the model
history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

epochs=list(range(len(acc)))

plt.plot(epochs,acc,label='train accuracy')
plt.plot(epochs,val_acc,label='val accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()

loss=history.history['loss']
val_loss=history.history['val_loss']
plt.plot(epochs,loss,label='train loss')
plt.plot(epochs,val_loss,label='val loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend()
plt.show()

y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_test_classes = np.argmax(y_test, axis=1)

from sklearn.metrics import confusion_matrix, classification_report
# Compute confusion matrix
conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)

# Print the confusion matrix
print("Confusion Matrix:")
print(conf_matrix)

from sklearn.metrics import classification_report

# For binary classification, adjust the target names
target_names = ['class_0', 'class_1']  # Replace with actual class names

# Generate the classification report
print("Classification Report:")
print(classification_report(y_test_classes, y_pred_classes, target_names=target_names))

#Correlation HeatMap
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()